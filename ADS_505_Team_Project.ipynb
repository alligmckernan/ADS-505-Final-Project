{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alligmckernan/ADS-505-Final-Project/blob/main/ADS_505_Team_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a16f9ab"
      },
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# ADS-505 Final Project — Miscarriage Prediction\n",
        "# =====================================================\n",
        "\n",
        "# 1. Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Import CalibrationDisplay after upgrading scikit-learn\n",
        "from sklearn.calibration import CalibrationDisplay\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Random seed\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Define the path to the dataset\n",
        "# The file is located directly in the /content directory, not in Google Drive.\n",
        "file_path = '/content/Miscarriage_Prediction_dataset_New_HA.csv'\n",
        "# Load the dataset\n",
        "\n",
        "# Changed the delimiter to semicolon\n",
        "df = pd.read_csv(file_path, delimiter=';')\n",
        "print(\"Shape:\", df.shape)\n",
        "\n",
        "# Convert 'BMI' column to numeric after replacing commas with periods\n",
        "df['BMI'] = df['BMI'].str.replace(',', '.', regex=False).astype(float)\n",
        "\n",
        "# Display the first few rows and the columns and their data types\n",
        "display(df.head())\n",
        "display(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2ed9082"
      },
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# Data overview\n",
        "# =====================================================\n",
        "print(df.info())\n",
        "print(df.describe(include='all').T)\n",
        "\n",
        "# Missing values\n",
        "missing = df.isna().mean().sort_values(ascending=False)\n",
        "print(\"\\nMissing values (top 10):\")\n",
        "print(missing.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAMhBPFXAUVD"
      },
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# Exploratory Data Analysis (per Shmueli et al., 2020 Ch. 3)\n",
        "# =====================================================\n",
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "TARGET_COL = 'Miscarriage/ No Miscarriage'\n",
        "\n",
        "# --- 1. Basic structure and summary ---\n",
        "print(\"\\nData structure:\")\n",
        "print(df.shape)\n",
        "print(df.info())\n",
        "print(\"\\nSummary statistics:\")\n",
        "display(df.describe(include='all').T)\n",
        "\n",
        "# --- 2. Correlation analysis (numeric variables only) ---\n",
        "corr_matrix = df.corr(numeric_only=True)\n",
        "corr_with_target = corr_matrix[TARGET_COL].sort_values(ascending=False)\n",
        "print(\"\\nCorrelation of numeric variables with target:\")\n",
        "print(corr_with_target.head(10))\n",
        "\n",
        "# --- 3. Select top correlated predictors (top 8 excluding target) ---\n",
        "top_corrs = corr_with_target.index[1:9]\n",
        "print(\"\\nTop correlated predictors:\", list(top_corrs))\n",
        "\n",
        "# --- 4. Histograms (Lab 1 style visual check) ---\n",
        "for col in top_corrs:\n",
        "    plt.figure(figsize=(6,3))\n",
        "    sns.histplot(df, x=col, hue=TARGET_COL, bins=30, kde=True, palette='muted')\n",
        "    plt.title(f\"Distribution of {col} by Miscarriage Outcome\")\n",
        "    plt.xlabel(col); plt.ylabel(\"Count\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# --- 5. Boxplots for group comparison (Shmueli et al. §3.4) ---\n",
        "for col in top_corrs:\n",
        "    plt.figure(figsize=(6,3))\n",
        "    sns.boxplot(x=TARGET_COL, y=col, data=df, palette='Set2')\n",
        "    plt.title(f\"{col} vs Miscarriage Outcome\")\n",
        "    plt.xlabel(\"Outcome (0 = No Miscarriage, 1 = Miscarriage)\")\n",
        "    plt.ylabel(col)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# --- 6. Non-parametric test for mean/median differences (as in Labs) ---\n",
        "print(\"\\nMann–Whitney U Tests for Group Differences\")\n",
        "print(\"---------------------------------------------------\")\n",
        "for col in top_corrs:\n",
        "    group0 = df.loc[df[TARGET_COL]==0, col].dropna()\n",
        "    group1 = df.loc[df[TARGET_COL]==1, col].dropna()\n",
        "    stat, p = mannwhitneyu(group0, group1, alternative='two-sided')\n",
        "    signif = \"Significant\" if p < 0.05 else \"ns\"\n",
        "    print(f\"{col:<20}  U = {stat:>10.1f}  p = {p:>.4f}  → {signif}\")\n",
        "\n",
        "# --- 7. Correlation heatmap (Lab visualization) ---\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(df[top_corrs.tolist() + [TARGET_COL]].corr(), cmap='coolwarm', center=0, annot=False)\n",
        "plt.title(\"Correlation Matrix — Top Predictors and Target\")\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfuN48iUK_9E"
      },
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# DATA PREPROCESSING — Train/Test Split Only\n",
        "# =====================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Define target column\n",
        "TARGET_COL = 'Miscarriage/ No Miscarriage'  # <-- change to actual target name\n",
        "if TARGET_COL not in df.columns:\n",
        "    raise ValueError(f\"Target column '{TARGET_COL}' not found. Available: {df.columns.tolist()}\")\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop(columns=[TARGET_COL])\n",
        "y = df[TARGET_COL].astype(int)\n",
        "\n",
        "# Identify numeric and categorical columns\n",
        "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "cat_cols = [c for c in X.columns if c not in num_cols]\n",
        "print(\"Numeric columns:\", num_cols)\n",
        "print(\"Categorical columns:\", cat_cols)\n",
        "\n",
        "# Train/Test split (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n",
        "\n",
        "# Pipelines for preprocessing\n",
        "numeric_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "# Combine preprocessing\n",
        "preprocess = ColumnTransformer([\n",
        "    ('num', numeric_pipe, num_cols),\n",
        "    ('cat', categorical_pipe, cat_cols)\n",
        "])\n",
        "\n",
        "# Fit the preprocessor on train data only\n",
        "preprocess.fit(X_train)\n",
        "\n",
        "# Transform both sets\n",
        "X_train_prepared = preprocess.transform(X_train)\n",
        "X_test_prepared = preprocess.transform(X_test)\n",
        "\n",
        "print(\"Preprocessing complete.\")\n",
        "print(\"Transformed train shape:\", X_train_prepared.shape)\n",
        "print(\"Transformed test shape:\", X_test_prepared.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PSwHyWyPeg_b"
      },
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# MODELS — Logistic Regression & Random Forest (Train/Test only)\n",
        "# =====================================================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, classification_report, confusion_matrix,\n",
        "    RocCurveDisplay, PrecisionRecallDisplay\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "def evaluate_classifier(name, clf, X_tr, y_tr, X_te, y_te):\n",
        "    clf.fit(X_tr, y_tr)\n",
        "\n",
        "    # Probabilities & predictions\n",
        "    proba = clf.predict_proba(X_te)[:, 1]\n",
        "    preds = (proba >= 0.5).astype(int)\n",
        "\n",
        "    # Metrics\n",
        "    auc = roc_auc_score(y_te, proba)\n",
        "    print(f\"\\n=== {name} — Test Set ===\")\n",
        "    print(\"ROC-AUC:\", round(auc, 4))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, preds))\n",
        "    print(classification_report(y_te, preds, digits=4))\n",
        "\n",
        "    # Curves\n",
        "    RocCurveDisplay.from_predictions(y_te, proba)\n",
        "    plt.title(f'ROC Curve — {name}')\n",
        "    plt.show()\n",
        "\n",
        "    PrecisionRecallDisplay.from_predictions(y_te, proba)\n",
        "    plt.title(f'Precision-Recall — {name}')\n",
        "    plt.show()\n",
        "\n",
        "    # Simple calibration curve (version-safe)\n",
        "    prob_true, prob_pred = calibration_curve(y_te, proba, n_bins=10, strategy='uniform')\n",
        "    plt.plot(prob_pred, prob_true, marker='o')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "    plt.xlabel('Predicted probability')\n",
        "    plt.ylabel('Observed frequency')\n",
        "    plt.title(f'Calibration — {name}')\n",
        "    plt.show()\n",
        "\n",
        "    return auc, proba, preds, clf\n",
        "\n",
        "\n",
        "# ----------------- 1) Logistic Regression -----------------\n",
        "log_reg = LogisticRegression(\n",
        "    max_iter=2000,\n",
        "    solver='saga',\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "auc_lr, proba_lr, preds_lr, clf_lr = evaluate_classifier(\n",
        "    \"Logistic Regression\", log_reg, X_train_prepared, y_train, X_test_prepared, y_test\n",
        ")\n",
        "\n",
        "\n",
        "# ----------------- 2) Random Forest -----------------\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1\n",
        ")\n",
        "auc_rf, proba_rf, preds_rf, clf_rf = evaluate_classifier(\n",
        "    \"Random Forest\", rf, X_train_prepared, y_train, X_test_prepared, y_test\n",
        ")\n",
        "\n",
        "print(\"\\nAUC comparison:\", {\"LogReg_AUC\": round(auc_lr, 4), \"RF_AUC\": round(auc_rf, 4)})\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# FEATURE IMPORTANCE (Random Forest) with proper names\n",
        "# =====================================================\n",
        "# Build feature names from the fitted preprocessor\n",
        "\n",
        "num_names = preprocess.named_transformers_['num'].get_feature_names_out(num_cols) \\\n",
        "            if hasattr(preprocess.named_transformers_['num'], 'get_feature_names_out') else np.array(num_cols)\n",
        "\n",
        "ohe = preprocess.named_transformers_['cat'].named_steps['encoder'] if 'cat' in preprocess.named_transformers_ else None\n",
        "if ohe is not None and len(cat_cols) > 0:\n",
        "    cat_names = ohe.get_feature_names_out(cat_cols)\n",
        "    feature_names = np.concatenate([num_names, cat_names])\n",
        "else:\n",
        "    feature_names = np.array(num_names)\n",
        "\n",
        "# Show top 20 importances\n",
        "if hasattr(clf_rf, \"feature_importances_\"):\n",
        "    importances = clf_rf.feature_importances_\n",
        "    order = np.argsort(importances)[::-1][:20]\n",
        "    plt.barh(feature_names[order][::-1], importances[order][::-1])\n",
        "    plt.title(\"Top 20 Feature Importances — Random Forest\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Feature importances not available for this model.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88GSAEb13Usi"
      },
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# 3) Support Vector Machine (RBF)\n",
        "# =====================================================\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_rbf = SVC(\n",
        "    kernel='rbf',\n",
        "    C=1.0,               # regularization\n",
        "    gamma='scale',       # RBF bandwidth (auto scaling)\n",
        "    probability=True,    # needed for predict_proba and ROC/PR curves\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "auc_svm, proba_svm, preds_svm, clf_svm = evaluate_classifier(\n",
        "    \"SVM (RBF)\", svm_rbf, X_train_prepared, y_train, X_test_prepared, y_test\n",
        ")\n",
        "\n",
        "print(\"\\nAUC comparison (updated):\",\n",
        "      {\"LogReg_AUC\": round(auc_lr, 4),\n",
        "       \"RF_AUC\": round(auc_rf, 4),\n",
        "       \"SVM_RBF_AUC\": round(auc_svm, 4)})\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPF1jN26GQlkO7wQQ09MRK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}